# Pipeline de Dados - Produtos e Vendas
**Aluno:** David Gilmour Souza
**RA:** 1524681

## ğŸ“‹ DescriÃ§Ã£o da SoluÃ§Ã£o

Este pipeline ETL processa dados de produtos e vendas de uma empresa de e-commerce, aplicando transformaÃ§Ãµes, limpeza de dados e gerando relatÃ³rios analÃ­ticos.

## ğŸ—ï¸ Arquitetura

### Escolha: ETL (Extract, Transform, Load)

Optei pela abordagem ETL pelos seguintes motivos:
1. **Volume de dados moderado** - permite processamento em memÃ³ria
2. **TransformaÃ§Ãµes complexas** - melhor executadas antes do carregamento
3. **Qualidade dos dados** - validaÃ§Ã£o e limpeza antes da persistÃªncia
4. **Performance do banco** - evita sobrecarga com transformaÃ§Ãµes no PostgreSQL

## ğŸ”„ Fluxo do Pipeline

```
extract_produtos â”€â”
                  â”œâ”€> transform_data -> create_tables -> load_data -> generate_report -> detect_low_performance
extract_vendas â”€â”€â”€â”˜
```

## ğŸ“Š TransformaÃ§Ãµes Aplicadas

### Limpeza de Dados
- **Preco_Custo nulo:** Preenchido com mÃ©dia da categoria
- **Fornecedor nulo:** Preenchido com "NÃ£o Informado"
- **Preco_Venda nulo:** Calculado como Preco_Custo * 1.3 (margem de 30%)

### CÃ¡lculos
- **Receita_Total:** Quantidade_Vendida Ã— Preco_Venda
- **Margem_Lucro:** Preco_Venda - Preco_Custo
- **Mes_Venda:** ExtraÃ­do de Data_Venda (formato YYYY-MM)

## ğŸ“ˆ RelatÃ³rios Gerados

1. **Vendas por Categoria**
   - Total de quantidade vendida
   - Receita total
   - Margem mÃ©dia

2. **Produto Mais Vendido**
   - Nome do produto
   - Quantidade total vendida
   - Receita gerada

3. **AnÃ¡lise por Canal de Venda**
   - NÃºmero de vendas
   - Quantidade total
   - Receita por canal

4. **Margem de Lucro**
   - Margem mÃ©dia, mÃ­nima e mÃ¡xima por categoria

## ğŸ Desafio BÃ´nus

Implementei detecÃ§Ã£o de produtos com baixa performance:
- Identifica produtos com menos de 2 vendas
- Gera alertas via log
- Cria tabela `produtos_baixa_performance`

## ğŸš€ Como Executar

1. Copiar arquivos CSV para `/opt/airflow/dags/data/`
2. Configurar conexÃ£o PostgreSQL no Airflow
3. Ativar a DAG no Airflow UI
4. Executar manualmente ou aguardar schedule (6h da manhÃ£)

## âœ… ValidaÃ§Ãµes Implementadas

- VerificaÃ§Ã£o de existÃªncia de arquivos
- Contagem de registros em cada etapa
- Logs detalhados para debugging
- ValidaÃ§Ã£o de inserÃ§Ã£o no banco

## ğŸ“ ObservaÃ§Ãµes

- Todos os requisitos do exercÃ­cio foram atendidos
- CÃ³digo comentado para facilitar manutenÃ§Ã£o
- Tratamento de erros em todas as funÃ§Ãµes
- Logs informativos para monitoramento
