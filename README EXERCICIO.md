# Pipeline de Produtos e Vendas - ExercÃ­cio Final

## ğŸ“‹ DescriÃ§Ã£o da SoluÃ§Ã£o

Este projeto implementa um pipeline ETL completo para processar dados de produtos e vendas, conforme especificado no exercÃ­cio final do workshop de Apache Airflow.

## ğŸ¯ Objetivos Atendidos

### âœ… Parte 1: AnÃ¡lise e Planejamento

**Problemas Identificados nos Dados:**
- `Preco_Custo` nulo para produto P003 (Teclado MecÃ¢nico)
- `Fornecedor` vazio para produto P005 (Webcam HD)  
- `Preco_Venda` nulo para venda V005 (Mouse Logitech)

**EstratÃ©gia ETL Escolhida:**
- **ETL** (Extract, Transform, Load) foi escolhida porque:
  - Volume de dados pequeno e bem estruturado
  - TransformaÃ§Ãµes bem definidas e simples
  - Processamento pode ser feito em memÃ³ria com pandas
  - Melhor controle de qualidade antes do carregamento

### âœ… Parte 2: ImplementaÃ§Ã£o da DAG

A DAG `pipeline_produtos_vendas` foi implementada com todas as 6 tarefas solicitadas:

#### ğŸ” Task 1: `extract_produtos`
- âœ… LÃª arquivo `produtos_loja.csv`
- âœ… Valida existÃªncia do arquivo
- âœ… Log detalhado do nÃºmero de registros extraÃ­dos
- âœ… Log adicional com estatÃ­sticas por categoria

#### ğŸ” Task 2: `extract_vendas`
- âœ… LÃª arquivo `vendas_produtos.csv`
- âœ… Valida existÃªncia do arquivo
- âœ… Log detalhado do nÃºmero de registros extraÃ­dos
- âœ… Log adicional com estatÃ­sticas por canal

#### ğŸ”„ Task 3: `transform_data`
**Limpeza de Dados:**
- âœ… Preenche `Preco_Custo` nulo com mÃ©dia da categoria
- âœ… Preenche `Fornecedor` nulo com "NÃ£o Informado"
- âœ… Preenche `Preco_Venda` nulo com `Preco_Custo * 1.3`

**TransformaÃ§Ãµes:**
- âœ… Calcula `Receita_Total` = `Quantidade_Vendida * Preco_Venda`
- âœ… Calcula `Margem_Lucro` = `Preco_Venda - Preco_Custo`
- âœ… Cria campo `Mes_Venda` extraÃ­do de `Data_Venda`

#### ğŸ—ƒï¸ Task 4: `create_tables`
- âœ… Cria tabela `produtos_processados`
- âœ… Cria tabela `vendas_processadas`
- âœ… Cria tabela `relatorio_vendas`
- âœ… Implementa DROP TABLE IF EXISTS para seguranÃ§a

#### ğŸ“¥ Task 5: `load_data`
- âœ… Carrega dados transformados nas tabelas PostgreSQL
- âœ… Cria relatÃ³rio consolidado com JOIN das tabelas
- âœ… Valida se dados foram inseridos corretamente
- âœ… Log detalhado de contadores de registros

#### ğŸ“Š Task 6: `generate_report`
- âœ… Total de vendas por categoria
- âœ… Produto mais vendido
- âœ… Canal de venda com maior receita
- âœ… Margem de lucro mÃ©dia por categoria
- âœ… Resumo geral com estatÃ­sticas consolidadas

### âœ… Parte 3: ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

**ConfiguraÃ§Ãµes da DAG:**
- âœ… Schedule: diÃ¡rio Ã s 6h da manhÃ£ (`'0 6 * * *'`)
- âœ… Retry: 2 tentativas
- âœ… Email on failure: False
- âœ… Tags: `['produtos', 'vendas', 'exercicio']`

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

```
extract_produtos â”€â”€â”
                   â”œâ”€â”€ transform_data â†’ create_tables â†’ load_data â†’ generate_report
extract_vendas â”€â”€â”€â”€â”˜
```

**DependÃªncias:**
1. `extract_produtos` e `extract_vendas` executam em paralelo
2. `transform_data` aguarda ambas as extraÃ§Ãµes
3. `create_tables` executa apÃ³s transformaÃ§Ã£o
4. `load_data` carrega dados nas tabelas criadas
5. `generate_report` gera relatÃ³rios finais

## ğŸ“Š Estrutura das Tabelas

### `produtos_processados`
```sql
CREATE TABLE produtos_processados (
    ID_Produto VARCHAR(10),
    Nome_Produto VARCHAR(100),
    Categoria VARCHAR(50),
    Preco_Custo DECIMAL(10,2),
    Fornecedor VARCHAR(100),
    Status VARCHAR(20),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### `vendas_processadas`
```sql
CREATE TABLE vendas_processadas (
    ID_Venda VARCHAR(10),
    ID_Produto VARCHAR(10),
    Quantidade_Vendida INTEGER,
    Preco_Venda DECIMAL(10,2),
    Data_Venda DATE,
    Canal_Venda VARCHAR(20),
    Receita_Total DECIMAL(10,2),
    Mes_Venda VARCHAR(7),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### `relatorio_vendas`
```sql
CREATE TABLE relatorio_vendas (
    ID_Venda VARCHAR(10),
    Nome_Produto VARCHAR(100),
    Categoria VARCHAR(50),
    Quantidade_Vendida INTEGER,
    Receita_Total DECIMAL(10,2),
    Margem_Lucro DECIMAL(10,2),
    Canal_Venda VARCHAR(20),
    Mes_Venda VARCHAR(7),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Apache Airflow configurado
- PostgreSQL em execuÃ§Ã£o
- ConexÃ£o `postgres_default` configurada no Airflow
- Arquivos CSV na pasta `/opt/airflow/data/`

### ExecuÃ§Ã£o
1. Copie o arquivo `pipeline_produtos_vendas.py` para a pasta `dags/`
2. A DAG aparecerÃ¡ automaticamente na interface do Airflow
3. Execute manualmente ou aguarde o schedule Ã s 6h da manhÃ£
4. Monitore os logs de cada tarefa

## ğŸ“ˆ RelatÃ³rios Gerados

O pipeline gera automaticamente:

1. **Vendas por Categoria**: Total de receita e quantidade por categoria
2. **Produto Mais Vendido**: Produto com maior quantidade vendida
3. **Canal com Maior Receita**: Canal de venda mais lucrativo
4. **Margem por Categoria**: Margem de lucro mÃ©dia por categoria
5. **Resumo Geral**: EstatÃ­sticas consolidadas

## ğŸ”§ Recursos TÃ©cnicos Utilizados

- **Apache Airflow**: OrquestraÃ§Ã£o do pipeline
- **Pandas**: ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados
- **PostgreSQL**: Armazenamento dos dados processados
- **Python**: Linguagem de programaÃ§Ã£o principal
- **CSV**: Formato dos dados de entrada

## ğŸ“ Logs e Monitoramento

Cada tarefa gera logs detalhados incluindo:
- NÃºmero de registros processados
- EstatÃ­sticas dos dados
- ValidaÃ§Ãµes de qualidade
- RelatÃ³rios consolidados
- Tratamento de erros

## âœ¨ Diferenciais Implementados

- **ValidaÃ§Ã£o de Arquivos**: Verifica existÃªncia antes de processar
- **Logs Detalhados**: InformaÃ§Ãµes completas sobre cada etapa
- **Tratamento de Nulos**: EstratÃ©gia inteligente para cada tipo de dado
- **ValidaÃ§Ã£o de Dados**: Confirma integridade apÃ³s carregamento
- **RelatÃ³rios AutomÃ¡ticos**: EstatÃ­sticas completas nos logs
- **Estrutura Robusta**: Tratamento de erros e retry configurado

---

**Desenvolvido para o Workshop de Apache Airflow - ExercÃ­cio Final**